{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/processed/headlines_cl_sent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47554, 19)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace = True)\n",
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset = ['clean_hl_words'], inplace = True)\n",
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45211, 19)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Two lists  of words that are used when a man or woman is present, based on Danielle Sucher's https://github.com/DanielleSucher/Jailbreak-the-Patriarchy\n",
    "# male_words=set(['guy','spokesman','chairman',\"men's\",'men','him',\"he's\",'his','boy','boyfriend','boyfriends','boys','brother','brothers','dad','dads','dude','father','fathers','fiance','gentleman','gentlemen','god','grandfather','grandpa','grandson','groom','he','himself','husband','husbands','king','male','man','mr','nephew','nephews','priest','prince','son','sons','uncle','uncles','waiter','widower','widowers'])\n",
    "\n",
    "themes = {'1':'female_words', '2':'female_bias_words','3':'male_words', '4':'discrimination_words',\n",
    "         '5':'male_bias_words', '6':'empowerement_words', '7':'violence_words'}\n",
    "\n",
    "female_words=set(['heroine','spokeswoman','chairwoman',\"women's\",'actress','women',\"she's\",'her','aunt',\n",
    "                  'aunts','bride','daughter','daughters','female','fiancee','girl','girlfriend','girlfriends',\n",
    "                  'girls','granddaughter','grandma','grandmother','herself','ladies','lady','lady',\n",
    "                  'mom','moms','mother','mothers','mrs','ms','niece','nieces','priestess','princess',\n",
    "                  'she','sister','sisters','waitress','widow','widows','wife','wives','woman', 'beautiful', \n",
    "                  'beauty', 'she', 'housewife', 'gender', 'pregnant', 'queen', 'madam', 'mum', 'mummy', \n",
    "                  'mums', 'mistress', \"nurse\", \"miss\", \"ex\"])\n",
    "\n",
    "female_bias_words = set(['weight', 'beauty', 'frail', 'weak', 'modest', 'virgin', \"slut\", \"whore\", \"prostitute\"\n",
    "                  'sex', 'feminine', 'sensitive', 'emotional', 'gentle', 'soft', \n",
    "                  'pretty', 'bitch', 'sexual', 'shopping','shop', \"model\",\n",
    "                  'sale', 'cook', 'cooking', 'sexual', 'baby', 'child', 'breast', 'breasts'\n",
    "                 ,'affectionate', 'affection', 'cheer', 'emotion', 'emotions', 'feel', 'feeling'\n",
    "                 , 'kind', 'kinship', 'modest', 'bossy', 'family', 'new born', 'newborn', 'new-born', \"irrational\",\n",
    "                 'nurture', 'nurtures', 'nurturing', 'pleasant', 'submissive', 'tender', 'cry', 'cries',\n",
    "                 'crying', 'obedient', \"accuse\", \"lose\",  \"love\", \"domestic\", \"victim\", \"mistress\", \"powerless\",\n",
    "                \"kid\", \"fear\", \"afraid\", \"marriage\", \"marry\", \"married\", \"wedding\", \"body\", \"kiss\", \"caress\", \"kissing\", \n",
    "                \"seduce\", \"seductive\", \"angel\",\"teen\", \"young\", \"sex\", \"good\", \"home\"])\n",
    "\n",
    "male_words = set(['hero', 'man',  'men', 'his', 'him', 'he', 'husband', 'father', 'male', 'son', 'god',\n",
    "                  'prince', 'king', 'mr', 'sir', 'brother', 'grandfather', 'uncle', 'nephew', 'master', 'patriarch',\n",
    "                 'chairman', 'chairmen', \"boy\",\"boyfriend\", \"save\"])\n",
    "\n",
    "discrimination_words = set(['race', 'caste', 'casteless', 'black', 'SC', 'ST', 'african american', 'white', 'colour', \n",
    "                            'color', \"brown\", \"asian\", \"native\", \"racial\", \"minority\", \"ethnic\", \"ethnicity\"])\n",
    "\n",
    "male_bias_words = set([\"active\", \"adventurous\", \"aggression\",'aggressive', \"ambition\", \"assert\", 'assertive',\n",
    "                       \"athlete\", 'athletic', \"battle\", \"champion\", \"decisive\", 'head', 'dominate', 'dominant',\n",
    "                        \"driven\", 'confident', 'strong', 'force', 'master', 'superior', 'strength', 'bold', \n",
    "                       'ambitious', 'power', 'intelligent', 'greedy', 'hostile', 'uncaring', 'logic', 'logical', 'rational',\n",
    "                       \"fearless\",'stubborn', 'independent', 'objective', \"charismatic\"])\n",
    "\n",
    "empowerement_words = set(['chairperson', 'leader','leadership',  'chairwoman', 'minister', 'power','powerful', 'authority', \n",
    "                          'queen', 'manager', 'success', 'successful', 'successes', 'career', 'job',\n",
    "                         'CEO','CFO', 'chief', 'officer', 'employment', 'employed', 'millionaire', \n",
    "                          'wealth', 'wealthy', 'strong', 'strength', 'courage','achievement', 'achievements', \n",
    "                          'achieve', 'goal', 'ambition', 'ambitious', 'passionate','passion', 'badass', \n",
    "                          'confident', 'confidence', 'breakthrough', \"inspirational\", \"educated\"\n",
    "                         'inspiring', 'inspiration', 'inspire', 'empower', 'empowered', 'empowerement',\n",
    "                         'genius', 'expert', 'mastery', 'owner', 'businesswoman', 'intelligent', 'smart', \n",
    "                          'clever', 'wise', 'worth', 'role model', 'role-model', 'activist', \"pay\", \"work\", \n",
    "                          \"business\", \"win\", \"award\", \"appoint\", \"lead\", \"star\", \"boss\", \"dream\",'goddess', \n",
    "                          \"actor\", 'queen', \"launch\"])\n",
    "\n",
    "politics_words = set([\"trump\", \"biden\", \"kamala\", \"harris\", \"joe\", \"vote\", \"election\", \"president\", \"elect\"])\n",
    "\n",
    "violence_words = set([\"find\", \"allegedly\", \"fire\", \"life\", 'violent', 'violence', 'crime', 'rape','rapist', 'raped', 'murder','kill', 'killed','killer',\n",
    "                     'murdered', 'murderer', 'attack', 'alleged', 'criminal', 'stab', 'knife', 'gun', 'guns', 'knives',\n",
    "                     'blood', 'bloodshed', 'court', 'rage', 'outrage', 'rob', 'steal', 'robber', 'stealer', 'beater', \"beaten\",\n",
    "                     'domestic violence', 'aggression', 'aggressor', 'war', 'battle', 'abduction', 'assault', 'assaulted',\n",
    "                     'drug', 'abuse', 'child abuse', 'prison', 'fraud', 'human traffic', 'homicide', 'organised crime',\n",
    "                     'organized crime', 'genocide', 'fight', 'manslaughter', 'terrorist', 'weapon', 'smuggl', 'shoplift',\n",
    "                     'vandalism', 'crime', 'theft', 'penalty', 'prison sentence', 'detained', 'guilty', 'trial',\n",
    "                     'defense', 'defend', 'armed', 'jail', 'illegal', 'accomplice',\n",
    "                     'alcohol', 'allegation', 'arson', 'bail', 'battery', 'dead', 'death', 'deadly', 'corrupt', 'killer', \n",
    "                     'sex crime', 'wanted', \"arrest\", \"police\", \"die\", \"charge\", \"suspect\", \"shoot\", \"sentence\", \"cop\", \"hit\", \n",
    "                     \"break\", \"beat\", \"judge\", \"kidnap\", \"law\", \"corruption\", \"gang\", \"suicide\", \"critically injured\", 'harassment', \"run\"])\n",
    "\n",
    "female_bias = female_words.union(female_bias_words)\n",
    "male_bias = male_words.union(male_bias_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.MultiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hl_words =[]\n",
    "all_marked_words = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_marked_words =  female_words.union(female_bias_words).union(male_words).union(discrimination_words).union(male_bias_words).union(empowerement_words).union(violence_words)\n",
    "# #all_marked_words = ast.literal_eval(all_marked_words)\n",
    "# #list(female_bias)\n",
    "# all_marked_words = list(all_marked_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def addedges(list):\n",
    "#     edges = []\n",
    "#     for i in combinations(list,2):\n",
    "#         edges.append(i)\n",
    "#     G.add_edges_from(edges) \n",
    "#     print('added edge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def usefulwordassociations(list):\n",
    "#     new_list = [x for x in list if x in all_marked_words]\n",
    "#     return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_hl_words(all_hl_words):\n",
    "#     for index,value in enumerate(all_hl_words):\n",
    "#         if len(value) == 1:\n",
    "#             all_hl_words.remove(value)\n",
    "\n",
    "#     for index,value in enumerate(all_hl_words):\n",
    "#         if value.isalpha() == False:\n",
    "#             all_hl_words.remove(value)\n",
    "#     return all_hl_words       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cleanwordassociations(list):\n",
    "#     new_list = [x for x in list if x.isalpha == False]\n",
    "#     new_list = [x for x in new_list if len(x)>1]\n",
    "#     return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def createfullnetwork(df):\n",
    "    G = nx.MultiGraph()\n",
    "    all_hl_words = []\n",
    "    for i in range(len(df)):\n",
    "        word_associations = []\n",
    "        all_hl_words += clean_hl_words(ast.literal_eval(df['clean_hl_words'][i]))\n",
    "        \n",
    "        #all_hl_words = clean_hl_words(all_hl_words)\n",
    "        #word_associations = cleanwordassociations(ast.literal_eval(df['clean_hl_words'][i]))\n",
    "        \n",
    "        word_associations = ast.literal_eval(df['clean_hl_words'][i])\n",
    "        \n",
    "        #print(type(word_associations))\n",
    "        #addedges(word_associations)\n",
    "        \n",
    "        edges = []\n",
    "        for i in combinations(word_associations,2):\n",
    "            edges.append(i)\n",
    "        G.add_edges_from(edges) \n",
    "        \n",
    "    #print('added edge')\n",
    "    G.add_nodes_from(all_hl_words)\n",
    "    print(len(G.nodes)) \n",
    "    print(len(G.edges))\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getusefulnodes(list):\n",
    "#     new_list = [x for x in list if x in all_marked_words]\n",
    "#     return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[231:750].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2170\n",
      "14212\n"
     ]
    }
   ],
   "source": [
    "g_test, all_hl_words = createfullnetwork(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_hl_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34311\n",
      "1173780\n"
     ]
    }
   ],
   "source": [
    "g = createfullnetwork(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u, v, d in g_test.edges(data=True):\n",
    "    d['weight'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createWeightedGraph(g_test):\n",
    "    G = nx.Graph()\n",
    "    for u,v,data in g_test.edges(data=True):\n",
    "        w = data['weight'] if 'weight' in data else 1.0\n",
    "        if G.has_edge(u,v):\n",
    "            G[u][v]['weight'] += int(w)\n",
    "        else:\n",
    "            G.add_edge(u, v, weight=w)\n",
    "    return G\n",
    "\n",
    "#G.add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_weighted = createWeightedGraph(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = pd.read_csv('../data/processed/words_freq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>say</td>\n",
       "      <td>2146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>new</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>man</td>\n",
       "      <td>1774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>trump</td>\n",
       "      <td>1573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>black</td>\n",
       "      <td>1235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   word  frequency\n",
       "0           0    say       2146\n",
       "1           1    new       1940\n",
       "2           2    man       1774\n",
       "3           3  trump       1573\n",
       "4           4  black       1235"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = []\n",
    "nx.set_node_attributes(G, frequency, \"frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in g_weighted.nodes(data=True):\n",
    "    node = u[0]\n",
    "    if len(freq[freq['word']== str(u[0])])>0:\n",
    "        g_weighted.nodes[str(node)]['frequency'] = int(freq[freq['word']== str(u[0])]['frequency'].values[0])\n",
    "   # print(u[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frequency': 937}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_weighted.nodes['die']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crown</td>\n",
       "      <td>v</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>crown</td>\n",
       "      <td>di</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>crown</td>\n",
       "      <td>diana</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>le</td>\n",
       "      <td>di</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>le</td>\n",
       "      <td>diana</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12603</th>\n",
       "      <td>supply</td>\n",
       "      <td>problem</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12606</th>\n",
       "      <td>problem</td>\n",
       "      <td>reckon</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12868</th>\n",
       "      <td>monthly</td>\n",
       "      <td>archives</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12871</th>\n",
       "      <td>monthly</td>\n",
       "      <td>archive</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13092</th>\n",
       "      <td>archives</td>\n",
       "      <td>tag</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>795 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         source    target  weight\n",
       "0         crown         v       2\n",
       "6         crown        di       2\n",
       "7         crown     diana       3\n",
       "65           le        di       2\n",
       "66           le     diana       2\n",
       "...         ...       ...     ...\n",
       "12603    supply   problem       2\n",
       "12606   problem    reckon       2\n",
       "12868   monthly  archives       4\n",
       "12871   monthly   archive       3\n",
       "13092  archives       tag       2\n",
       "\n",
       "[795 rows x 3 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_test = nx.to_pandas_edgelist(G)\n",
    "edges_test[edges_test['weight']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32584\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "g = createfullnetwork(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "70\n",
      "357\n"
     ]
    }
   ],
   "source": [
    "G = createfullnetwork(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g_test.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Node attributes to add -\n",
    "1. which dictionary it belongs to\n",
    "2. frequency of node\n",
    "3. frequency of edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx; \n",
    "from networkx.readwrite import json_graph;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "connections = json_graph.node_link_data(g_weighted)\n",
    "connections_json = json.dumps(connections, indent = 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed/word_connections.json\", \"w\") as outfile: \n",
    "    outfile.write(connections_json) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231     ['crown', 'v', 'realt', 'le', 'foto', 'dei', '...\n",
       "738     ['crown', 'riveler', 'nuovi', 'segreti', 'anch...\n",
       "2798    ['play', 'princess', 'diana', 'netflix', 'crown']\n",
       "3885    ['fact', 'crown', 'star', 'emma', 'corrin', 'l...\n",
       "3970    ['princess', 'diana', 'camilla', 'parker', 'bo...\n",
       "Name: clean_hl_words, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df[(df['headline'].str.lower().str.contains('diana')) & (df['headline'].str.lower().str.contains('crown'))].head()['clean_hl_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.number_of_edges('diana', 'crown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32592"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g_filtered.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df['useful_word_associations'] = np.empty((len(df), 0)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# time\n",
    "# def calcfilterednetwork(df):\n",
    "#     all_hl_words = []\n",
    "#     all_useful_hl_words = []\n",
    "#     for i in range(len(df)):\n",
    "#         all_hl_words += getusefulnodes(ast.literal_eval(df['clean_hl_words'][i]))\n",
    "#         df['useful_word_associations'].iloc[i] = usefulwordassociations(ast.literal_eval(df['clean_hl_words'][i]))\n",
    "        \n",
    "#         if len(df['useful_word_associations'][i])>=1:\n",
    "#             addedges(df['useful_word_associations'][i])\n",
    "            \n",
    "            \n",
    "#     G.add_nodes_from(all_hl_words)\n",
    "    \n",
    "#     print(len(all_hl_words))  \n",
    "#     return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g_filtered = calcfilterednetwork(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Themes addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_file(filename):\n",
    "    with open(filename) as f:\n",
    "        js_graph = json.load(f)\n",
    "    return json_graph.node_link_graph(js_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = read_json_file(\"../data/processed/word_connections_4.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme = \"\"\n",
    "nx.set_node_attributes(g, theme, \"theme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in g.nodes(data=True):\n",
    "    node = u[0]\n",
    "    if node in female_bias:\n",
    "         g.nodes[str(node)]['theme'] = \"female_bias\"\n",
    "    elif node in male_bias:\n",
    "         g.nodes[str(node)]['theme'] = \"male_bias\"\n",
    "    elif node in empowerement_words:\n",
    "         g.nodes[str(node)]['theme'] = \"empowerment\"\n",
    "    elif node in violence_words:\n",
    "         g.nodes[str(node)]['theme'] = \"violence\"\n",
    "    elif node in politics_words:\n",
    "         g.nodes[str(node)]['theme'] = \"politics\"\n",
    "    elif node in discrimination_words:\n",
    "         g.nodes[str(node)]['theme'] = \"race\"\n",
    "    else:\n",
    "        g.nodes[str(node)]['theme'] = \"other\"\n",
    "            \n",
    "#     if len(freq[freq['word']== str(u[0])])>0:\n",
    "#         g_weighted.nodes[str(node)]['frequency'] = int(freq[freq['word']== str(u[0])]['frequency'].values[0])\n",
    "   # print(u[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frequency': 160, 'theme': 'other'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.nodes['crown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_edge_attributes(g, theme, \"theme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u,v,data in g.edges(data=True):\n",
    "#     print(data['theme'])\n",
    "#     print(g[u][v]['weight'])\n",
    "    if u in female_bias:\n",
    "         g[u][v]['theme'] = \"female_bias\"\n",
    "    elif u in male_bias:\n",
    "         g[u][v]['theme'] = \"male_bias\"\n",
    "    elif u in empowerement_words:\n",
    "         g[u][v]['theme'] = \"empowerment\"\n",
    "    elif u in violence_words:\n",
    "         g[u][v]['theme'] = \"violence\"\n",
    "    elif u in politics_words:\n",
    "         g[u][v]['theme'] = \"politics\"\n",
    "    elif u in discrimination_words:\n",
    "         g[u][v]['theme'] = \"race\"\n",
    "    else:\n",
    "        g[u][v]['theme'] = \"other\"\n",
    "#     w = data['weight'] if 'weight' in data else 1.0\n",
    "#     if G.has_edge(u,v):\n",
    "#         G[u][v]['weight'] += int(w)\n",
    "#     else:\n",
    "#         G.add_edge(u, v, weight=w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': 173.0, 'theme': 'politics'}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edges[\"joe\", \"biden\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections = json_graph.node_link_data(g)\n",
    "connections_json = json.dumps(connections, indent = 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed/word_connections_4_themes.json\", \"w\") as outfile: \n",
    "    outfile.write(connections_json) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = [(u,v) for u, v, data in g.edges(data=True) if data[\"weight\"] <= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75697"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95671"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.remove_edges_from(remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19974"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections = json_graph.node_link_data(g)\n",
    "connections_json = json.dumps(connections, indent = 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed/word_connections_4_themes_filtered.json\", \"w\") as outfile: \n",
    "    outfile.write(connections_json) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
